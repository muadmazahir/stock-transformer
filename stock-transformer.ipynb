{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6rc3WOE3UJJ"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 4149,
     "status": "ok",
     "timestamp": 1756203382022,
     "user": {
      "displayName": "Muad Mazahir",
      "userId": "03860219212751714631"
     },
     "user_tz": -60
    },
    "id": "H9MMIffX3HDX"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "def set_seed(seed=1337):\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "class TimeSeriesTransformer(nn.Module):\n",
    "    def __init__(self, d_in, window, d_model=128, n_heads=4, n_layers=3, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.window = window\n",
    "        self.proj = nn.Linear(d_in, d_model)\n",
    "        self.pos  = nn.Parameter(torch.randn(1, window, d_model) * 0.01)\n",
    "        enc = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=n_heads,\n",
    "            dim_feedforward=4*d_model, dropout=dropout,\n",
    "            batch_first=True, norm_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(enc, num_layers=n_layers)\n",
    "        self.head = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, x):                # x: (B, L, d_in)\n",
    "        z = self.proj(x) + self.pos[:, :x.size(1)]\n",
    "        z = self.encoder(z)              # (B, L, d_model)\n",
    "        z = z[:, -1, :]                  # use last step\n",
    "        return self.head(z).squeeze(-1)  # (B,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ou47U2rN3XCm"
   },
   "source": [
    "# Download and Prepare Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 737,
     "status": "ok",
     "timestamp": 1756203388377,
     "user": {
      "displayName": "Muad Mazahir",
      "userId": "03860219212751714631"
     },
     "user_tz": -60
    },
    "id": "JLBX5jsG3ino"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1756203389377,
     "user": {
      "displayName": "Muad Mazahir",
      "userId": "03860219212751714631"
     },
     "user_tz": -60
    },
    "id": "tqsZT_az3kSn"
   },
   "outputs": [],
   "source": [
    "def download_prices(tickers, start=None, end=None, interval=\"1d\", adjust=False):\n",
    "    \"\"\"Download OHLCV data from Yahoo Finance.\"\"\"\n",
    "    data = yf.download(tickers=tickers, start=start, end=end, interval=interval,\n",
    "                       auto_adjust=adjust, group_by='ticker', threads=True, progress=False)\n",
    "    if data.empty:\n",
    "        raise ValueError(\"No data returned. Check tickers/interval/date range.\")\n",
    "    return data\n",
    "\n",
    "def save_prices(data: pd.DataFrame, tickers, out_path: Path, wide=False):\n",
    "    \"\"\"Save downloaded prices to CSV in wide or tidy format.\"\"\"\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if isinstance(tickers, (list, tuple)) and len(tickers) > 1:\n",
    "        if wide:\n",
    "            data.to_csv(out_path)\n",
    "        else:\n",
    "            tidy = data.stack(level=0).reset_index()\n",
    "            tidy = tidy.rename(columns={\"level_1\": \"Ticker\"})\n",
    "            tidy.to_csv(out_path, index=False)\n",
    "    else:\n",
    "        if isinstance(data.columns, pd.MultiIndex):\n",
    "            data.columns = [' '.join(col).strip() for col in data.columns.values]\n",
    "        data.to_csv(out_path)\n",
    "    return out_path\n",
    "\n",
    "def maybe_save_actions(tickers, start, end, out_dir: Path, which: str):\n",
    "    \"\"\"Save dividend or split history for given tickers.\"\"\"\n",
    "    for t in tickers:\n",
    "        tk = yf.Ticker(t)\n",
    "        if which == \"dividends\":\n",
    "            df = tk.dividends\n",
    "        else:\n",
    "            df = tk.splits\n",
    "        if df is None or df.empty:\n",
    "            continue\n",
    "        df = df.loc[(df.index >= (start or df.index.min())) & (df.index <= (end or df.index.max()))]\n",
    "        file = out_dir / f\"{t.lower()}_{which}.csv\"\n",
    "        df.to_csv(file, header=[which.capitalize()])\n",
    "        print(f\"Saved {which} for {t}: {file}\")\n",
    "\n",
    "def fetch_and_save(tickers, start=None, end=None, interval=\"1d\", adjust=False,\n",
    "                   dividends=False, splits=False, out=\"prices.csv\", wide=False):\n",
    "    \"\"\"\n",
    "    Fetch historical price data from Yahoo Finance and save to CSV.\n",
    "\n",
    "    Parameters:\n",
    "      tickers (list[str] or str): One or more ticker symbols.\n",
    "      start, end (str or None): YYYY-MM-DD date range.\n",
    "      interval (str): Data interval, e.g., '1d', '1wk', '1mo'.\n",
    "      adjust (bool): Adjust OHLC for dividends/splits.\n",
    "      dividends (bool): Save dividend history to separate CSVs.\n",
    "      splits (bool): Save split history to separate CSVs.\n",
    "      out (str): Output CSV path for price data.\n",
    "      wide (bool): Save multi-ticker data in wide format (default False).\n",
    "    \"\"\"\n",
    "    if isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "    out_path = Path(out)\n",
    "    data = download_prices(tickers, start=start, end=end, interval=interval, adjust=adjust)\n",
    "    saved_file = save_prices(data, tickers, out_path, wide=wide)\n",
    "    print(f\"Saved prices to: {saved_file.resolve()}\")\n",
    "    if dividends:\n",
    "        maybe_save_actions(tickers, start, end, out_path.parent, \"dividends\")\n",
    "    if splits:\n",
    "        maybe_save_actions(tickers, start, end, out_path.parent, \"splits\")\n",
    "    return saved_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39500,
     "status": "ok",
     "timestamp": 1756203432213,
     "user": {
      "displayName": "Muad Mazahir",
      "userId": "03860219212751714631"
     },
     "user_tz": -60
    },
    "id": "NuMmVePw3lhU",
    "outputId": "d418283b-0039-48a0-fd98-8e6b122ff10f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13041,
     "status": "ok",
     "timestamp": 1756203466986,
     "user": {
      "displayName": "Muad Mazahir",
      "userId": "03860219212751714631"
     },
     "user_tz": -60
    },
    "id": "5fsZUTGa3nD1",
    "outputId": "2f2a713d-5fdb-429e-b729-33994532d19d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1595752501.py:16: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  tidy = data.stack(level=0).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved prices to: /content/drive/MyDrive/stock-data.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('drive/MyDrive/stock-data.csv')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers = [\n",
    "  \"NVDA\",\"MSFT\",\"AAPL\",\"AMZN\",\"META\",\"AVGO\",\"GOOGL\",\"GOOG\",\"TSLA\",\"ELV\",\n",
    "  \"JPM\",\"WMT\",\"ORCL\",\"V\",\"LLY\",\"MA\",\"NFLX\",\"XOM\",\"COST\",\"JNJ\",\n",
    "  \"PLTR\",\"HD\",\"ABBV\",\"PG\",\"BAC\",\"CVX\",\"KO\",\"AMD\",\"TMUS\",\"GE\",\n",
    "  \"UNH\",\"CSCO\",\"PM\",\"WFC\",\"MS\",\"CRM\",\"ABT\",\"LIN\",\"IBM\",\"GS\",\n",
    "  \"MCD\",\"AXP\",\"MRK\",\"DIS\",\"RTX\",\"T\",\"PEP\",\"INTU\",\"UBER\",\"CAT\",\n",
    "  \"VZ\",\"TMO\",\"NOW\",\"BA\",\"BKNG\",\"BLK\",\"TXN\",\"SCHW\",\"C\",\"ANET\",\n",
    "  \"ISRG\",\"SPGI\",\"QCOM\",\"GEV\",\"AMGN\",\"ACN\",\"BSX\",\"DHR\",\"ADBE\",\"NEE\",\n",
    "  \"TJX\",\"GILD\",\"SYK\",\"PGR\",\"PFE\",\"LOW\",\"COF\",\"HON\",\"ETN\",\"MU\",\n",
    "  \"BX\",\"APH\",\"DE\",\"UNP\",\"AMAT\",\"KKR\",\"LRCX\",\"CMCSA\",\"ADP\",\"COP\",\n",
    "  \"MDT\",\"PANW\",\"ADI\",\"KLAC\",\"SNPS\",\"NKE\",\"MO\",\"INTC\",\"CB\"\n",
    "]\n",
    "\n",
    "fetch_and_save(\n",
    "    tickers=tickers,\n",
    "    start=\"2019-01-01\",\n",
    "    end=\"2024-12-31\",\n",
    "    interval=\"1d\",\n",
    "    adjust=True,\n",
    "    out=\"./drive/MyDrive/stock-data.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1mbzAqt3wme"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1756203495975,
     "user": {
      "displayName": "Muad Mazahir",
      "userId": "03860219212751714631"
     },
     "user_tz": -60
    },
    "id": "zF3kf5cU3xyK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ====== 1) Feature engineering per ticker ======\n",
    "def add_features(g: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add new features to the dataset like \"\"\"\n",
    "    g = g.sort_values(\"Date\").copy()\n",
    "    g[\"logp\"]  = np.log(g[\"Close\"])\n",
    "    g[\"ret1\"]  = g[\"logp\"].diff()                       # next-day target base\n",
    "    g[\"hl_pct\"] = (g[\"High\"] - g[\"Low\"]) / g[\"Close\"]   # intraday range\n",
    "    g[\"vol_log\"] = np.log(g[\"Volume\"].replace(0, np.nan)).ffill()\n",
    "    g[\"vol_chg\"] = g[\"vol_log\"].diff()\n",
    "\n",
    "    # time (cyclical) encodings\n",
    "    dow = g[\"Date\"].dt.dayofweek\n",
    "    month = g[\"Date\"].dt.month\n",
    "    g[\"dow_sin\"]   = np.sin(2*np.pi * dow/7)\n",
    "    g[\"dow_cos\"]   = np.cos(2*np.pi * dow/7)\n",
    "    g[\"mth_sin\"]   = np.sin(2*np.pi * (month-1)/12)\n",
    "    g[\"mth_cos\"]   = np.cos(2*np.pi * (month-1)/12)\n",
    "\n",
    "    # drop first row (diff) NaNs\n",
    "    g = g.dropna().reset_index(drop=True)\n",
    "    return g\n",
    "\n",
    "# ====== 2) Split dates (pure temporal split) ======\n",
    "def temporal_split(df, train_end, val_end):\n",
    "    \"\"\"\n",
    "    Split the dataframe into three seperate dataframes (i.e train, val, and test) based on train_end and val_end times\n",
    "    \"\"\"\n",
    "    train = df[df[\"Date\"] <= pd.to_datetime(train_end)]\n",
    "    val   = df[(df[\"Date\"] > pd.to_datetime(train_end)) & (df[\"Date\"] <= pd.to_datetime(val_end))]\n",
    "    test  = df[df[\"Date\"] > pd.to_datetime(val_end)]\n",
    "    return train, val, test\n",
    "\n",
    "# ====== 3) Per-ticker standardization using train stats only ======\n",
    "def fit_scaler(train_df, feature_cols):\n",
    "    \"\"\"\n",
    "    return the mean and standard deiviation of each of the given columns of the given df\n",
    "    \"\"\"\n",
    "    stats = (train_df[feature_cols].mean(), train_df[feature_cols].std().replace(0,1.0))\n",
    "    return stats\n",
    "\n",
    "def apply_scaler(df, feature_cols, stats):\n",
    "    \"\"\"\n",
    "    Standardise the given columns of the given df using the given mean and standard deviation which was retrieved from the training set\n",
    "    \"\"\"\n",
    "    mu, sd = stats\n",
    "    df = df.copy()\n",
    "    df.loc[:, feature_cols] = (df[feature_cols] - mu) / sd\n",
    "    return df\n",
    "\n",
    "# ====== 4) Window maker ======\n",
    "def make_windows(feat_df, feature_cols, target_col, window=64, horizon=1):\n",
    "    \"\"\"\n",
    "    This creates a training and corresponding target arrays.\n",
    "\n",
    "    Uses window number of rows to predict target_col of current timestamp plus horizon target.\n",
    "\n",
    "    I.E, give window=64, target_col='ret1', and horizon=1, predict ret1 of t+1 using the t-64 rows.\n",
    "\n",
    "    Returns arrays X:(N,L,D), y:(N,), where (N=number of windows, L=window length (horixon), D=number of features (len(feature_cols)))\n",
    "    Predict target_col at t+horizon using features up to t (inclusive).\n",
    "    \"\"\"\n",
    "    vals = feat_df[feature_cols].values\n",
    "    target = feat_df[target_col].shift(-horizon).values  # predict next-day return\n",
    "    # last 'horizon' targets become NaN; drop them\n",
    "    valid_upto = len(feat_df) - horizon\n",
    "    X, y = [], []\n",
    "    for t in range(window, valid_upto):\n",
    "        X.append(vals[t-window:t, :])\n",
    "        y.append(target[t-1])  # target at current t (i.e., next-day)\n",
    "    X = np.stack(X).astype(np.float32)\n",
    "    y = np.array(y, dtype=np.float32)\n",
    "    return X, y\n",
    "\n",
    "# ====== 5) Dataset wrapper ======\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X)\n",
    "        self.y = torch.from_numpy(y)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4K-jeOoi30Vg"
   },
   "source": [
    "# Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1756203498840,
     "user": {
      "displayName": "Muad Mazahir",
      "userId": "03860219212751714631"
     },
     "user_tz": -60
    },
    "id": "0Xiu-Diu3zMa"
   },
   "outputs": [],
   "source": [
    "def build_datasets_with_scalers(\n",
    "    df_long,\n",
    "    window=64,\n",
    "    horizon=1,\n",
    "    train_end=\"2022-12-31\",\n",
    "    val_end=\"2023-12-31\",\n",
    "    tickers=None,\n",
    "    task=\"regression\",\n",
    "):\n",
    "    df = df_long.copy()\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "    if tickers is not None:\n",
    "        df = df[df[\"Ticker\"].isin(tickers)]\n",
    "\n",
    "    # add to the dataset new features\n",
    "    df_feat = (\n",
    "        df.groupby(\"Ticker\", group_keys=False)\n",
    "          .apply(add_features)\n",
    "          .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    feature_cols = [\"ret1\", \"hl_pct\", \"vol_chg\", \"dow_sin\", \"dow_cos\", \"mth_sin\", \"mth_cos\"]\n",
    "    target_col = \"ret1\"\n",
    "\n",
    "    # split data into train, validation, and test dfs based on datetime.\n",
    "    # I.E, the beginning of the dataset to the train_end datetime will be the training set, that point to the val_end datetime will be the validation set. The rest will be the testing set\n",
    "    train_long, val_long, test_long = temporal_split(df_feat, train_end, val_end)\n",
    "\n",
    "    Xy = {\"train\": {\"X\": [], \"y\": []}, \"val\": {\"X\": [], \"y\": []}, \"test\": {\"X\": [], \"y\": []}}\n",
    "    scalers = {}   # ticker -> (mu, sd)\n",
    "\n",
    "    for ticker, g_train in train_long.groupby(\"Ticker\"):\n",
    "        g_val  = val_long[val_long[\"Ticker\"] == ticker]\n",
    "        g_test = test_long[test_long[\"Ticker\"] == ticker]\n",
    "        if len(g_train) < window + horizon + 1:\n",
    "            continue\n",
    "\n",
    "        # get the mean and standard deviation of the training set\n",
    "        stats = fit_scaler(g_train, feature_cols)\n",
    "        scalers[ticker] = stats\n",
    "\n",
    "        # standardise all 3 dfs using the mean and standard deviation of the training set that we retrieved above\n",
    "        g_train_s = apply_scaler(g_train, feature_cols, stats)\n",
    "        g_val_s   = apply_scaler(g_val,   feature_cols, stats) if len(g_val)  else g_val\n",
    "        g_test_s  = apply_scaler(g_test,  feature_cols, stats) if len(g_test) else g_test\n",
    "\n",
    "        for name, g_s in [(\"train\", g_train_s), (\"val\", g_val_s), (\"test\", g_test_s)]:\n",
    "            if len(g_s) >= window + horizon + 1:\n",
    "                X, y = make_windows(g_s, feature_cols, target_col, window, horizon)\n",
    "                if task == \"direction\":\n",
    "                    y = (y > 0).astype(np.float32)\n",
    "                Xy[name][\"X\"].append(X); Xy[name][\"y\"].append(y)\n",
    "\n",
    "    def _stack(split):\n",
    "        if not Xy[split][\"X\"]:\n",
    "            return None, None\n",
    "        X = np.concatenate(Xy[split][\"X\"], axis=0).astype(np.float32)\n",
    "        y = np.concatenate(Xy[split][\"y\"], axis=0).astype(np.float32)\n",
    "        return X, y\n",
    "\n",
    "    X_train, y_train = _stack(\"train\")\n",
    "    X_val,   y_val   = _stack(\"val\")\n",
    "    X_test,  y_test  = _stack(\"test\")\n",
    "\n",
    "    train_ds = TimeSeriesDataset(X_train, y_train) if X_train is not None else None\n",
    "    val_ds   = TimeSeriesDataset(X_val,   y_val)   if X_val   is not None else None\n",
    "    test_ds  = TimeSeriesDataset(X_test,  y_test)  if X_test  is not None else None\n",
    "\n",
    "    meta = {\n",
    "        \"feature_cols\": feature_cols,\n",
    "        \"d_in\": len(feature_cols),\n",
    "        \"window\": window,\n",
    "        \"horizon\": horizon,\n",
    "        \"task\": task,\n",
    "        \"tickers\": sorted(train_long[\"Ticker\"].unique().tolist()),\n",
    "        \"train_end\": str(pd.to_datetime(train_end).date()),\n",
    "        \"val_end\": str(pd.to_datetime(val_end).date()),\n",
    "    }\n",
    "    return train_ds, val_ds, test_ds, meta, scalers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3eythPae32_h"
   },
   "source": [
    "# Training + validation + early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1756203501191,
     "user": {
      "displayName": "Muad Mazahir",
      "userId": "03860219212751714631"
     },
     "user_tz": -60
    },
    "id": "LiXyqseA35HN"
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    train_loader, val_loader, meta,\n",
    "    d_model=128, n_heads=4, n_layers=3, dropout=0.1,\n",
    "    epochs=50, lr=2e-3, weight_decay=1e-4, patience=5, device=None, seed=1337\n",
    "):\n",
    "    set_seed(seed)\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = TimeSeriesTransformer(\n",
    "        d_in=meta[\"d_in\"], window=meta[\"window\"],\n",
    "        d_model=d_model, n_heads=n_heads, n_layers=n_layers, dropout=dropout\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.MSELoss() if meta[\"task\"] == \"regression\" else nn.BCEWithLogitsLoss()\n",
    "    optimizer = AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=2)\n",
    "\n",
    "    best_val = float(\"inf\")\n",
    "    best_state = None\n",
    "    wait = 0\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        # ---- train\n",
    "        model.train()\n",
    "        tr_loss, n_tr = 0.0, 0\n",
    "        for xb, yb in train_loader:\n",
    "            xb = xb.to(device); yb = yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(xb)\n",
    "            loss = criterion(out, yb)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            tr_loss += loss.item() * xb.size(0)\n",
    "            n_tr += xb.size(0)\n",
    "        tr_loss /= max(1, n_tr)\n",
    "\n",
    "        # ---- validate\n",
    "        model.eval()\n",
    "        vl_loss, n_vl = 0.0, 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                xb = xb.to(device); yb = yb.to(device)\n",
    "                out = model(xb)\n",
    "                loss = criterion(out, yb)\n",
    "                vl_loss += loss.item() * xb.size(0)\n",
    "                n_vl += xb.size(0)\n",
    "        vl_loss /= max(1, n_vl)\n",
    "        scheduler.step(vl_loss)\n",
    "\n",
    "        print(f\"epoch {epoch:03d} | train {tr_loss:.4f} | val {vl_loss:.4f} | lr {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "        if vl_loss + 1e-8 < best_val:\n",
    "            best_val = vl_loss\n",
    "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                print(\"early stopping.\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "taGVcNgw37sc"
   },
   "source": [
    "# Test evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1756203505348,
     "user": {
      "displayName": "Muad Mazahir",
      "userId": "03860219212751714631"
     },
     "user_tz": -60
    },
    "id": "RhAOK8EV37Cg"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, meta, device=None):\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in data_loader:\n",
    "            xb = xb.to(device)\n",
    "            out = model(xb).cpu().numpy()\n",
    "            y_pred.append(out)\n",
    "            y_true.append(yb.numpy())\n",
    "    y_true = np.concatenate(y_true); y_pred = np.concatenate(y_pred)\n",
    "\n",
    "    if meta[\"task\"] == \"regression\":\n",
    "        mse = np.mean((y_pred - y_true)**2)\n",
    "        mae = np.mean(np.abs(y_pred - y_true))\n",
    "        print(f\"Test MSE: {mse:.6f} | MAE: {mae:.6f}\")\n",
    "        return {\"mse\": mse, \"mae\": mae, \"y_true\": y_true, \"y_pred\": y_pred}\n",
    "    else:\n",
    "        prob = 1/(1+np.exp(-y_pred))\n",
    "        pred = (prob > 0.5).astype(np.float32)\n",
    "        acc = (pred == y_true).mean()\n",
    "        print(f\"Test Accuracy: {acc:.4f}\")\n",
    "        return {\"acc\": acc, \"y_true\": y_true, \"y_pred\": y_pred, \"prob\": prob}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IpuweHxC4A41"
   },
   "source": [
    "# Inference helper for a specific ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1756203507232,
     "user": {
      "displayName": "Muad Mazahir",
      "userId": "03860219212751714631"
     },
     "user_tz": -60
    },
    "id": "bX6NVOgz4Co4"
   },
   "outputs": [],
   "source": [
    "def latest_window_for_ticker(df_long, ticker, meta, scalers):\n",
    "    \"\"\"\n",
    "    This rebuilds features for a ticker, applies the train-split scaler you used, and returns the last window to predict the next day.\n",
    "    \"\"\"\n",
    "    df = df_long[df_long[\"Ticker\"] == ticker].copy()\n",
    "    if df.empty or ticker not in scalers:\n",
    "        raise ValueError(f\"No data or scaler for {ticker}\")\n",
    "\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "    g = add_features(df)\n",
    "    mu, sd = scalers[ticker]\n",
    "    feat = g[meta[\"feature_cols\"]].copy()\n",
    "    feat = (feat - mu) / sd\n",
    "    if len(feat) < meta[\"window\"]:\n",
    "        raise ValueError(f\"Not enough history for window={meta['window']}\")\n",
    "    x = feat.values[-meta[\"window\"]:, :].astype(np.float32)  # (L, D)\n",
    "    x = torch.from_numpy(x).unsqueeze(0)  # (1, L, D)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4BY1BCs4I3Z"
   },
   "source": [
    "# End-to-end usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2888,
     "status": "ok",
     "timestamp": 1756203550230,
     "user": {
      "displayName": "Muad Mazahir",
      "userId": "03860219212751714631"
     },
     "user_tz": -60
    },
    "id": "A0FRGqaj4J--",
    "outputId": "78a183b8-4b8f-4dcd-b133-2afe6a048520"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-490303508.py:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(add_features)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"./drive/MyDrive/stock-data.csv\") # read data from csv file\n",
    "\n",
    "# Build datasets/loaders\n",
    "train_ds, val_ds, test_ds, meta, scalers = build_datasets_with_scalers(\n",
    "    df,                       # your tidy df (Date, Ticker, OHLCV)\n",
    "    window=64, horizon=1,\n",
    "    train_end=\"2022-12-31\",\n",
    "    val_end=\"2023-12-31\",\n",
    "    tickers=None,             # or subset like [\"AAPL\",\"MSFT\",\"NVDA\"]\n",
    "    task=\"regression\"         # or \"direction\"\n",
    ")\n",
    "\n",
    "\n",
    "BATCH = 256\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True, drop_last=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH, shuffle=False)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 175721,
     "status": "ok",
     "timestamp": 1756203753244,
     "user": {
      "displayName": "Muad Mazahir",
      "userId": "03860219212751714631"
     },
     "user_tz": -60
    },
    "id": "cLxgJWGL4vRM",
    "outputId": "405402b5-d5ce-4756-db2f-12fb060c12d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 001 | train 1.1440 | val 0.5770 | lr 2.00e-03\n",
      "epoch 002 | train 0.9298 | val 0.5603 | lr 2.00e-03\n",
      "epoch 003 | train 0.8813 | val 0.5617 | lr 2.00e-03\n",
      "epoch 004 | train 0.8543 | val 0.5843 | lr 2.00e-03\n",
      "epoch 005 | train 0.8327 | val 0.5562 | lr 2.00e-03\n",
      "epoch 006 | train 0.8131 | val 0.5712 | lr 2.00e-03\n",
      "epoch 007 | train 0.7876 | val 0.5729 | lr 2.00e-03\n",
      "epoch 008 | train 0.7611 | val 0.5871 | lr 1.00e-03\n",
      "epoch 009 | train 0.7048 | val 0.6239 | lr 1.00e-03\n",
      "epoch 010 | train 0.6741 | val 0.5874 | lr 1.00e-03\n",
      "epoch 011 | train 0.6499 | val 0.6670 | lr 5.00e-04\n",
      "early stopping.\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "model = train_model(train_loader, val_loader, meta,\n",
    "                    d_model=128, n_heads=4, n_layers=3, dropout=0.1,\n",
    "                    epochs=50, lr=2e-3, patience=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 983,
     "status": "ok",
     "timestamp": 1756203759054,
     "user": {
      "displayName": "Muad Mazahir",
      "userId": "03860219212751714631"
     },
     "user_tz": -60
    },
    "id": "l-0TXOhP4yVP",
    "outputId": "50290b12-81df-49da-c1ed-0ea81cc293b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.661646 | MAE: 0.565058\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "_ = evaluate(model, test_loader, meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54,
     "status": "ok",
     "timestamp": 1756203764294,
     "user": {
      "displayName": "Muad Mazahir",
      "userId": "03860219212751714631"
     },
     "user_tz": -60
    },
    "id": "jpSdY1oy4z30",
    "outputId": "0e6380c0-59c2-46a1-9dc5-dd8ded4d65f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted next-day return for AAPL: 0.07556751370429993\n"
     ]
    }
   ],
   "source": [
    "# Inference for a ticker (predict next-day return)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "x_latest = latest_window_for_ticker(df, \"AAPL\", meta, scalers).to(device)\n",
    "with torch.no_grad():\n",
    "    pred_ret = model(x_latest).item()\n",
    "print(\"Predicted next day return for AAPL:\", pred_ret)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNEZdOKup8JGlnYnPaLppOa",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
